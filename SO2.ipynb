{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SO2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moo7XLt9OHSB",
        "outputId": "c2c70962-0fd3-4dee-d73b-ce8f9970b5a7"
      },
      "source": [
        "!pip install scikit-multilearn\n",
        "!pip install scikit-multilearn --upgrade\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "from sqlalchemy import create_engine # database connection\n",
        "import datetime as dt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from datetime import datetime\n",
        "from skmultilearn.adapt import mlknn\n",
        "from skmultilearn.problem_transform import ClassifierChain\n",
        "from skmultilearn.problem_transform import BinaryRelevance\n",
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-multilearn in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already up-to-date: scikit-multilearn in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EgRGGjXQ25X",
        "outputId": "b224c310-3269-4579-8b51-5c7c50bb904a"
      },
      "source": [
        "text_path='/content/drive/MyDrive/colab_SMAI/test1.txt'\n",
        "df=pd.read_csv(text_path, names=['Id', 'Title','Body','Tag'],skiprows=1,nrows=1200000)\n",
        "df['Tag'] = df['Tag'].fillna(\"\")\n",
        "df['Tag'] = df['Tag'].astype(str)\n",
        "\n",
        "df['cleaned_tags']=df['Tag'].str.lower().replace('\\n','')\n",
        "df['cleaned_tags']=df['cleaned_tags'].apply(lambda x: str(x).encode('ascii', 'ignore').decode('ascii'))\n",
        "df['cleaned_tags']=df['cleaned_tags'].str.replace('\\d+', '')\n",
        "df['cleaned_tags']=df['cleaned_tags'].str.replace(' +', ' ')\n",
        "\n",
        "junk_chars = \"[]{}.-\"\n",
        "for c in junk_chars:\n",
        "  df['cleaned_tags']=df['cleaned_tags'].str.replace(c, '')\n",
        "\n",
        "qus_list=[]\n",
        "qus_with_code = 0\n",
        "len_before_preprocessing = 0 \n",
        "len_after_preprocessing = 0 \n",
        "cnt = 0\n",
        "for index,row in df.iterrows():\n",
        "    title, body, tags = row[\"Title\"], row[\"Body\"], row[\"cleaned_tags\"]\n",
        "    if '<code>' in body:\n",
        "        qus_with_code+=1\n",
        "    len_before_preprocessing+=len(title) + len(body)\n",
        "    body=re.sub('<code>(.*?)</code>', '', body, flags=re.MULTILINE|re.DOTALL)\n",
        "    body = re.sub('<.*?>', ' ', str(body.encode('utf-8')))\n",
        "    title=title.encode('utf-8')\n",
        "    question=str(title)+\" \"+str(body)\n",
        "    question=re.sub(r'[^A-Za-z]+',' ',question)\n",
        "    words=word_tokenize(str(question.lower()))\n",
        "    question=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c'))\n",
        "    qus_list.append(question)\n",
        "    len_after_preprocessing += len(question)\n",
        "    cnt = cnt + 1\n",
        "    if (cnt%25000 == 0):\n",
        "      print(\"Qstn body processed : \", cnt)\n",
        "\n",
        "df[\"question\"] = qus_list\n",
        "avg_len_before_preprocessing=(len_before_preprocessing*1.0)/df.shape[0]\n",
        "avg_len_after_preprocessing=(len_after_preprocessing*1.0)/df.shape[0]\n",
        "print(\" total dataset size: \"+ str(len(df)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Qstn body processed :  25000\n",
            "Qstn body processed :  50000\n",
            "Qstn body processed :  75000\n",
            "Qstn body processed :  100000\n",
            "Qstn body processed :  125000\n",
            "Qstn body processed :  150000\n",
            "Qstn body processed :  175000\n",
            "Qstn body processed :  200000\n",
            "Qstn body processed :  225000\n",
            "Qstn body processed :  250000\n",
            "Qstn body processed :  275000\n",
            "Qstn body processed :  300000\n",
            "Qstn body processed :  325000\n",
            "Qstn body processed :  350000\n",
            "Qstn body processed :  375000\n",
            "Qstn body processed :  400000\n",
            "Qstn body processed :  425000\n",
            "Qstn body processed :  450000\n",
            "Qstn body processed :  475000\n",
            "Qstn body processed :  500000\n",
            "Qstn body processed :  525000\n",
            "Qstn body processed :  550000\n",
            "Qstn body processed :  575000\n",
            "Qstn body processed :  600000\n",
            "Qstn body processed :  625000\n",
            "Qstn body processed :  650000\n",
            "Qstn body processed :  675000\n",
            "Qstn body processed :  700000\n",
            "Qstn body processed :  725000\n",
            "Qstn body processed :  750000\n",
            "Qstn body processed :  775000\n",
            "Qstn body processed :  800000\n",
            "Qstn body processed :  825000\n",
            "Qstn body processed :  850000\n",
            "Qstn body processed :  875000\n",
            "Qstn body processed :  900000\n",
            "Qstn body processed :  925000\n",
            "Qstn body processed :  950000\n",
            "Qstn body processed :  975000\n",
            "Qstn body processed :  1000000\n",
            "Qstn body processed :  1025000\n",
            "Qstn body processed :  1050000\n",
            "Qstn body processed :  1075000\n",
            "Qstn body processed :  1100000\n",
            "Qstn body processed :  1125000\n",
            "Qstn body processed :  1150000\n",
            "Qstn body processed :  1175000\n",
            "Qstn body processed :  1200000\n",
            " total dataset size: 1200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LenUnISVtNTY",
        "outputId": "4575c806-052a-43da-9f1f-f3b0706f70dc"
      },
      "source": [
        "preprocessed_df = df[[\"question\",\"cleaned_tags\"]]\n",
        "preprocessed_df = preprocessed_df[:30000]\n",
        "print(\"Shape of preprocessed data :\", preprocessed_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of preprocessed data : (30000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpcFyx6lY7qC"
      },
      "source": [
        "def tags_to_consider(n):\n",
        "    tag_i_sum = y_multilabel.sum(axis=0).tolist()[0]\n",
        "    sorted_tags_i = sorted(range(len(tag_i_sum)), key=lambda i: tag_i_sum[i], reverse=True)\n",
        "    yn_multilabel=y_multilabel[:,sorted_tags_i[:n]]\n",
        "    return yn_multilabel\n",
        "\n",
        "def questions_covered_fn(numb):\n",
        "    yn_multilabel = tags_to_consider(numb)\n",
        "    x= yn_multilabel.sum(axis=1)\n",
        "    return (np.count_nonzero(x==0))\n",
        "\n",
        "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(), binary='true')\n",
        "y_multilabel = vectorizer.fit_transform(preprocessed_df['cleaned_tags'])\n",
        "\n",
        "questions_covered = []\n",
        "total_tags=y_multilabel.shape[1]\n",
        "total_qus=preprocessed_df.shape[0]\n",
        "for i in range(100, total_tags, 100):\n",
        "    questions_covered.append(np.round(((total_qus-questions_covered_fn(i))/total_qus)*100,3))\n",
        "\n",
        "yx_multilabel = tags_to_consider(100)\n",
        "X_train, X_test, y_train, y_test = train_test_split(preprocessed_df, yx_multilabel, test_size = 0.1,random_state = 42)\n",
        "vectorizer = TfidfVectorizer(min_df=0.00009, max_features=20000, tokenizer = lambda x: x.split(), ngram_range=(1,3))\n",
        "X_train_multilabel = vectorizer.fit_transform(X_train['question'])\n",
        "X_test_multilabel = vectorizer.transform(X_test['question'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "A4lC0BzFjEo-",
        "outputId": "1ad1c406-c03b-4e91-f13a-92a586cdba00"
      },
      "source": [
        "\n",
        "cparam = [.65, .7, 1]\n",
        "for cval in cparam:\n",
        "  print(\" ------------- for : \"+ str(cval)+ \"---------------\")\n",
        "  clf_lsvc = OneVsRestClassifier(LinearSVC(C=cval))\n",
        "  clf_lsvc.fit(X_train_multilabel, y_train)\n",
        "  y_pred = clf_lsvc.predict(X_test_multilabel)\n",
        "  print(\"Accuracy :\",metrics.accuracy_score(y_test,y_pred))\n",
        "  print(\"Macro f1 score :\",metrics.f1_score(y_test, y_pred, average = 'macro'))\n",
        "  print(\"Micro f1 scoore :\",metrics.f1_score(y_test, y_pred, average = 'micro'))\n",
        "  print(\"Hamming loss :\",metrics.hamming_loss(y_test,y_pred))\n",
        "\"\"\"\n",
        "   ------------- for : 0.65---------------\n",
        "Accuracy : 0.43256666666666665\n",
        "Macro f1 score : 0.501832360150235\n",
        "Micro f1 scoore : 0.567803603355797\n",
        "Hamming loss : 0.00838\n",
        " ------------- for : 0.7---------------\n",
        "Accuracy : 0.4325333333333333\n",
        "Macro f1 score : 0.5040089974405092\n",
        "Micro f1 scoore : 0.5686298056303718\n",
        "Hamming loss : 0.008381666666666667\n",
        " ------------- for : 1---------------\n",
        "Accuracy : 0.4307666666666667\n",
        "Macro f1 score : 0.5091321291199462\n",
        "Micro f1 scoore : 0.5703628348592744\n",
        "Hamming loss : 0.008446666666666667\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ------------- for : 0.65---------------\n",
            "Accuracy : 0.1\n",
            "Macro f1 score : 0.0\n",
            "Micro f1 scoore : 0.0\n",
            "Hamming loss : 0.013666666666666667\n",
            " ------------- for : 0.7---------------\n",
            "Accuracy : 0.1\n",
            "Macro f1 score : 0.0\n",
            "Micro f1 scoore : 0.0\n",
            "Hamming loss : 0.013666666666666667\n",
            " ------------- for : 1---------------\n",
            "Accuracy : 0.1\n",
            "Macro f1 score : 0.01\n",
            "Micro f1 scoore : 0.047619047619047616\n",
            "Hamming loss : 0.013333333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n   ------------- for : 0.65---------------\\nAccuracy : 0.43256666666666665\\nMacro f1 score : 0.501832360150235\\nMicro f1 scoore : 0.567803603355797\\nHamming loss : 0.00838\\n ------------- for : 0.7---------------\\nAccuracy : 0.4325333333333333\\nMacro f1 score : 0.5040089974405092\\nMicro f1 scoore : 0.5686298056303718\\nHamming loss : 0.008381666666666667\\n ------------- for : 1---------------\\nAccuracy : 0.4307666666666667\\nMacro f1 score : 0.5091321291199462\\nMicro f1 scoore : 0.5703628348592744\\nHamming loss : 0.008446666666666667\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUUCSkYY7Fon",
        "outputId": "f72cb803-b2ca-49de-c51b-4311f09b4c2a"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svct=SVC(kernel='rbf')\n",
        "svc = OneVsRestClassifier(svct)\n",
        "\n",
        "svc.fit(X_train_multilabel, y_train)\n",
        "y_pred=svc.predict(X_test_multilabel)\n",
        "print('Accuracy Score:')\n",
        "print(metrics.accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score:\n",
            "0.3626666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnt4FQxYynuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c3a9cf-643b-493c-bb47-b11c30af6655"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "param_grid = {'estimator__C': [1, 100, 1000],\n",
        "              'estimator__gamma': ['scale','auto',1,.1, .01,.001 ],\n",
        "              'estimator__kernel': ['rbf']\n",
        "              }\n",
        "svc = OneVsRestClassifier(SVC())\n",
        "rbf = model_selection.GridSearchCV(estimator=svc, param_grid=param_grid, verbose = 10)\n",
        "rbf.fit(X_train_multilabel, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "[CV] estimator__C=1, estimator__gamma=scale, estimator__kernel=rbf ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  estimator__C=1, estimator__gamma=scale, estimator__kernel=rbf, score=0.204, total=   3.5s\n",
            "[CV] estimator__C=1, estimator__gamma=scale, estimator__kernel=rbf ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  estimator__C=1, estimator__gamma=scale, estimator__kernel=rbf, score=0.185, total=   3.5s\n",
            "[CV] estimator__C=1, estimator__gamma=scale, estimator__kernel=rbf ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    7.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  estimator__C=1, estimator__gamma=scale, estimator__kernel=rbf, score=0.111, total=   3.6s\n",
            "[CV] estimator__C=1, estimator__gamma=scale, estimator__kernel=rbf ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   10.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  estimator__C=1, estimator__gamma=scale, estimator__kernel=rbf, score=0.130, total=   3.5s\n",
            "[CV] estimator__C=1, estimator__gamma=scale, estimator__kernel=rbf ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   14.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  estimator__C=1, estimator__gamma=scale, estimator__kernel=rbf, score=0.148, total=   3.6s\n",
            "[CV] estimator__C=1, estimator__gamma=auto, estimator__kernel=rbf ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  estimator__C=1, estimator__gamma=auto, estimator__kernel=rbf, score=0.204, total=   0.2s\n",
            "[CV] estimator__C=1, estimator__gamma=auto, estimator__kernel=rbf ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   18.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  estimator__C=1, estimator__gamma=auto, estimator__kernel=rbf, score=0.185, total=   0.3s\n",
            "[CV] estimator__C=1, estimator__gamma=auto, estimator__kernel=rbf ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   18.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  estimator__C=1, estimator__gamma=auto, estimator__kernel=rbf, score=0.111, total=   0.3s\n",
            "[CV] estimator__C=1, estimator__gamma=auto, estimator__kernel=rbf ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   18.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  estimator__C=1, estimator__gamma=auto, estimator__kernel=rbf, score=0.130, total=   0.3s\n",
            "[CV] estimator__C=1, estimator__gamma=auto, estimator__kernel=rbf ....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   18.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  estimator__C=1, estimator__gamma=auto, estimator__kernel=rbf, score=0.148, total=   0.3s\n",
            "[CV] estimator__C=1, estimator__gamma=1, estimator__kernel=rbf .......\n",
            "[CV]  estimator__C=1, estimator__gamma=1, estimator__kernel=rbf, score=0.204, total=   3.3s\n",
            "[CV] estimator__C=1, estimator__gamma=1, estimator__kernel=rbf .......\n",
            "[CV]  estimator__C=1, estimator__gamma=1, estimator__kernel=rbf, score=0.185, total=   3.4s\n",
            "[CV] estimator__C=1, estimator__gamma=1, estimator__kernel=rbf .......\n",
            "[CV]  estimator__C=1, estimator__gamma=1, estimator__kernel=rbf, score=0.111, total=   3.5s\n",
            "[CV] estimator__C=1, estimator__gamma=1, estimator__kernel=rbf .......\n",
            "[CV]  estimator__C=1, estimator__gamma=1, estimator__kernel=rbf, score=0.130, total=   3.4s\n",
            "[CV] estimator__C=1, estimator__gamma=1, estimator__kernel=rbf .......\n",
            "[CV]  estimator__C=1, estimator__gamma=1, estimator__kernel=rbf, score=0.148, total=   3.3s\n",
            "[CV] estimator__C=1, estimator__gamma=0.1, estimator__kernel=rbf .....\n",
            "[CV]  estimator__C=1, estimator__gamma=0.1, estimator__kernel=rbf, score=0.204, total=   2.2s\n",
            "[CV] estimator__C=1, estimator__gamma=0.1, estimator__kernel=rbf .....\n",
            "[CV]  estimator__C=1, estimator__gamma=0.1, estimator__kernel=rbf, score=0.185, total=   2.3s\n",
            "[CV] estimator__C=1, estimator__gamma=0.1, estimator__kernel=rbf .....\n",
            "[CV]  estimator__C=1, estimator__gamma=0.1, estimator__kernel=rbf, score=0.111, total=   2.3s\n",
            "[CV] estimator__C=1, estimator__gamma=0.1, estimator__kernel=rbf .....\n",
            "[CV]  estimator__C=1, estimator__gamma=0.1, estimator__kernel=rbf, score=0.130, total=   2.3s\n",
            "[CV] estimator__C=1, estimator__gamma=0.1, estimator__kernel=rbf .....\n",
            "[CV]  estimator__C=1, estimator__gamma=0.1, estimator__kernel=rbf, score=0.148, total=   2.2s\n",
            "[CV] estimator__C=1, estimator__gamma=0.01, estimator__kernel=rbf ....\n",
            "[CV]  estimator__C=1, estimator__gamma=0.01, estimator__kernel=rbf, score=0.204, total=   1.0s\n",
            "[CV] estimator__C=1, estimator__gamma=0.01, estimator__kernel=rbf ....\n",
            "[CV]  estimator__C=1, estimator__gamma=0.01, estimator__kernel=rbf, score=0.185, total=   1.0s\n",
            "[CV] estimator__C=1, estimator__gamma=0.01, estimator__kernel=rbf ....\n",
            "[CV]  estimator__C=1, estimator__gamma=0.01, estimator__kernel=rbf, score=0.111, total=   1.0s\n",
            "[CV] estimator__C=1, estimator__gamma=0.01, estimator__kernel=rbf ....\n",
            "[CV]  estimator__C=1, estimator__gamma=0.01, estimator__kernel=rbf, score=0.130, total=   1.0s\n",
            "[CV] estimator__C=1, estimator__gamma=0.01, estimator__kernel=rbf ....\n",
            "[CV]  estimator__C=1, estimator__gamma=0.01, estimator__kernel=rbf, score=0.148, total=   1.0s\n",
            "[CV] estimator__C=1, estimator__gamma=0.001, estimator__kernel=rbf ...\n",
            "[CV]  estimator__C=1, estimator__gamma=0.001, estimator__kernel=rbf, score=0.204, total=   0.3s\n",
            "[CV] estimator__C=1, estimator__gamma=0.001, estimator__kernel=rbf ...\n",
            "[CV]  estimator__C=1, estimator__gamma=0.001, estimator__kernel=rbf, score=0.185, total=   0.3s\n",
            "[CV] estimator__C=1, estimator__gamma=0.001, estimator__kernel=rbf ...\n",
            "[CV]  estimator__C=1, estimator__gamma=0.001, estimator__kernel=rbf, score=0.111, total=   0.3s\n",
            "[CV] estimator__C=1, estimator__gamma=0.001, estimator__kernel=rbf ...\n",
            "[CV]  estimator__C=1, estimator__gamma=0.001, estimator__kernel=rbf, score=0.130, total=   0.3s\n",
            "[CV] estimator__C=1, estimator__gamma=0.001, estimator__kernel=rbf ...\n",
            "[CV]  estimator__C=1, estimator__gamma=0.001, estimator__kernel=rbf, score=0.148, total=   0.3s\n",
            "[CV] estimator__C=100, estimator__gamma=scale, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=100, estimator__gamma=scale, estimator__kernel=rbf, score=0.204, total=   3.5s\n",
            "[CV] estimator__C=100, estimator__gamma=scale, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=100, estimator__gamma=scale, estimator__kernel=rbf, score=0.185, total=   3.6s\n",
            "[CV] estimator__C=100, estimator__gamma=scale, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=100, estimator__gamma=scale, estimator__kernel=rbf, score=0.111, total=   3.6s\n",
            "[CV] estimator__C=100, estimator__gamma=scale, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=100, estimator__gamma=scale, estimator__kernel=rbf, score=0.130, total=   3.6s\n",
            "[CV] estimator__C=100, estimator__gamma=scale, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=100, estimator__gamma=scale, estimator__kernel=rbf, score=0.148, total=   3.5s\n",
            "[CV] estimator__C=100, estimator__gamma=auto, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=100, estimator__gamma=auto, estimator__kernel=rbf, score=0.204, total=   0.7s\n",
            "[CV] estimator__C=100, estimator__gamma=auto, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=100, estimator__gamma=auto, estimator__kernel=rbf, score=0.185, total=   0.8s\n",
            "[CV] estimator__C=100, estimator__gamma=auto, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=100, estimator__gamma=auto, estimator__kernel=rbf, score=0.111, total=   0.8s\n",
            "[CV] estimator__C=100, estimator__gamma=auto, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=100, estimator__gamma=auto, estimator__kernel=rbf, score=0.130, total=   0.7s\n",
            "[CV] estimator__C=100, estimator__gamma=auto, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=100, estimator__gamma=auto, estimator__kernel=rbf, score=0.148, total=   0.7s\n",
            "[CV] estimator__C=100, estimator__gamma=1, estimator__kernel=rbf .....\n",
            "[CV]  estimator__C=100, estimator__gamma=1, estimator__kernel=rbf, score=0.204, total=   3.3s\n",
            "[CV] estimator__C=100, estimator__gamma=1, estimator__kernel=rbf .....\n",
            "[CV]  estimator__C=100, estimator__gamma=1, estimator__kernel=rbf, score=0.185, total=   3.4s\n",
            "[CV] estimator__C=100, estimator__gamma=1, estimator__kernel=rbf .....\n",
            "[CV]  estimator__C=100, estimator__gamma=1, estimator__kernel=rbf, score=0.111, total=   3.4s\n",
            "[CV] estimator__C=100, estimator__gamma=1, estimator__kernel=rbf .....\n",
            "[CV]  estimator__C=100, estimator__gamma=1, estimator__kernel=rbf, score=0.130, total=   3.4s\n",
            "[CV] estimator__C=100, estimator__gamma=1, estimator__kernel=rbf .....\n",
            "[CV]  estimator__C=100, estimator__gamma=1, estimator__kernel=rbf, score=0.148, total=   3.3s\n",
            "[CV] estimator__C=100, estimator__gamma=0.1, estimator__kernel=rbf ...\n",
            "[CV]  estimator__C=100, estimator__gamma=0.1, estimator__kernel=rbf, score=0.204, total=   2.7s\n",
            "[CV] estimator__C=100, estimator__gamma=0.1, estimator__kernel=rbf ...\n",
            "[CV]  estimator__C=100, estimator__gamma=0.1, estimator__kernel=rbf, score=0.185, total=   2.9s\n",
            "[CV] estimator__C=100, estimator__gamma=0.1, estimator__kernel=rbf ...\n",
            "[CV]  estimator__C=100, estimator__gamma=0.1, estimator__kernel=rbf, score=0.111, total=   2.9s\n",
            "[CV] estimator__C=100, estimator__gamma=0.1, estimator__kernel=rbf ...\n",
            "[CV]  estimator__C=100, estimator__gamma=0.1, estimator__kernel=rbf, score=0.130, total=   2.8s\n",
            "[CV] estimator__C=100, estimator__gamma=0.1, estimator__kernel=rbf ...\n",
            "[CV]  estimator__C=100, estimator__gamma=0.1, estimator__kernel=rbf, score=0.148, total=   2.7s\n",
            "[CV] estimator__C=100, estimator__gamma=0.01, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=100, estimator__gamma=0.01, estimator__kernel=rbf, score=0.204, total=   2.6s\n",
            "[CV] estimator__C=100, estimator__gamma=0.01, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=100, estimator__gamma=0.01, estimator__kernel=rbf, score=0.185, total=   2.7s\n",
            "[CV] estimator__C=100, estimator__gamma=0.01, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=100, estimator__gamma=0.01, estimator__kernel=rbf, score=0.111, total=   2.7s\n",
            "[CV] estimator__C=100, estimator__gamma=0.01, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=100, estimator__gamma=0.01, estimator__kernel=rbf, score=0.130, total=   2.7s\n",
            "[CV] estimator__C=100, estimator__gamma=0.01, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=100, estimator__gamma=0.01, estimator__kernel=rbf, score=0.148, total=   2.6s\n",
            "[CV] estimator__C=100, estimator__gamma=0.001, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=100, estimator__gamma=0.001, estimator__kernel=rbf, score=0.204, total=   2.3s\n",
            "[CV] estimator__C=100, estimator__gamma=0.001, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=100, estimator__gamma=0.001, estimator__kernel=rbf, score=0.185, total=   2.3s\n",
            "[CV] estimator__C=100, estimator__gamma=0.001, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=100, estimator__gamma=0.001, estimator__kernel=rbf, score=0.111, total=   2.3s\n",
            "[CV] estimator__C=100, estimator__gamma=0.001, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=100, estimator__gamma=0.001, estimator__kernel=rbf, score=0.130, total=   2.2s\n",
            "[CV] estimator__C=100, estimator__gamma=0.001, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=100, estimator__gamma=0.001, estimator__kernel=rbf, score=0.148, total=   2.2s\n",
            "[CV] estimator__C=1000, estimator__gamma=scale, estimator__kernel=rbf \n",
            "[CV]  estimator__C=1000, estimator__gamma=scale, estimator__kernel=rbf, score=0.204, total=   3.5s\n",
            "[CV] estimator__C=1000, estimator__gamma=scale, estimator__kernel=rbf \n",
            "[CV]  estimator__C=1000, estimator__gamma=scale, estimator__kernel=rbf, score=0.185, total=   3.5s\n",
            "[CV] estimator__C=1000, estimator__gamma=scale, estimator__kernel=rbf \n",
            "[CV]  estimator__C=1000, estimator__gamma=scale, estimator__kernel=rbf, score=0.111, total=   3.6s\n",
            "[CV] estimator__C=1000, estimator__gamma=scale, estimator__kernel=rbf \n",
            "[CV]  estimator__C=1000, estimator__gamma=scale, estimator__kernel=rbf, score=0.130, total=   3.6s\n",
            "[CV] estimator__C=1000, estimator__gamma=scale, estimator__kernel=rbf \n",
            "[CV]  estimator__C=1000, estimator__gamma=scale, estimator__kernel=rbf, score=0.148, total=   3.5s\n",
            "[CV] estimator__C=1000, estimator__gamma=auto, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=1000, estimator__gamma=auto, estimator__kernel=rbf, score=0.204, total=   1.9s\n",
            "[CV] estimator__C=1000, estimator__gamma=auto, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=1000, estimator__gamma=auto, estimator__kernel=rbf, score=0.185, total=   2.0s\n",
            "[CV] estimator__C=1000, estimator__gamma=auto, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=1000, estimator__gamma=auto, estimator__kernel=rbf, score=0.111, total=   2.0s\n",
            "[CV] estimator__C=1000, estimator__gamma=auto, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=1000, estimator__gamma=auto, estimator__kernel=rbf, score=0.130, total=   2.0s\n",
            "[CV] estimator__C=1000, estimator__gamma=auto, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=1000, estimator__gamma=auto, estimator__kernel=rbf, score=0.148, total=   1.9s\n",
            "[CV] estimator__C=1000, estimator__gamma=1, estimator__kernel=rbf ....\n",
            "[CV]  estimator__C=1000, estimator__gamma=1, estimator__kernel=rbf, score=0.204, total=   3.3s\n",
            "[CV] estimator__C=1000, estimator__gamma=1, estimator__kernel=rbf ....\n",
            "[CV]  estimator__C=1000, estimator__gamma=1, estimator__kernel=rbf, score=0.185, total=   3.4s\n",
            "[CV] estimator__C=1000, estimator__gamma=1, estimator__kernel=rbf ....\n",
            "[CV]  estimator__C=1000, estimator__gamma=1, estimator__kernel=rbf, score=0.111, total=   3.4s\n",
            "[CV] estimator__C=1000, estimator__gamma=1, estimator__kernel=rbf ....\n",
            "[CV]  estimator__C=1000, estimator__gamma=1, estimator__kernel=rbf, score=0.130, total=   3.4s\n",
            "[CV] estimator__C=1000, estimator__gamma=1, estimator__kernel=rbf ....\n",
            "[CV]  estimator__C=1000, estimator__gamma=1, estimator__kernel=rbf, score=0.148, total=   3.3s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.1, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=1000, estimator__gamma=0.1, estimator__kernel=rbf, score=0.204, total=   2.7s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.1, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=1000, estimator__gamma=0.1, estimator__kernel=rbf, score=0.185, total=   2.9s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.1, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=1000, estimator__gamma=0.1, estimator__kernel=rbf, score=0.111, total=   2.8s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.1, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=1000, estimator__gamma=0.1, estimator__kernel=rbf, score=0.130, total=   2.8s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.1, estimator__kernel=rbf ..\n",
            "[CV]  estimator__C=1000, estimator__gamma=0.1, estimator__kernel=rbf, score=0.148, total=   2.7s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.01, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=1000, estimator__gamma=0.01, estimator__kernel=rbf, score=0.204, total=   2.6s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.01, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=1000, estimator__gamma=0.01, estimator__kernel=rbf, score=0.185, total=   2.7s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.01, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=1000, estimator__gamma=0.01, estimator__kernel=rbf, score=0.111, total=   2.7s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.01, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=1000, estimator__gamma=0.01, estimator__kernel=rbf, score=0.130, total=   2.7s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.01, estimator__kernel=rbf .\n",
            "[CV]  estimator__C=1000, estimator__gamma=0.01, estimator__kernel=rbf, score=0.148, total=   2.6s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.001, estimator__kernel=rbf \n",
            "[CV]  estimator__C=1000, estimator__gamma=0.001, estimator__kernel=rbf, score=0.204, total=   2.6s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.001, estimator__kernel=rbf \n",
            "[CV]  estimator__C=1000, estimator__gamma=0.001, estimator__kernel=rbf, score=0.185, total=   2.7s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.001, estimator__kernel=rbf \n",
            "[CV]  estimator__C=1000, estimator__gamma=0.001, estimator__kernel=rbf, score=0.111, total=   2.7s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.001, estimator__kernel=rbf \n",
            "[CV]  estimator__C=1000, estimator__gamma=0.001, estimator__kernel=rbf, score=0.130, total=   2.7s\n",
            "[CV] estimator__C=1000, estimator__gamma=0.001, estimator__kernel=rbf \n",
            "[CV]  estimator__C=1000, estimator__gamma=0.001, estimator__kernel=rbf, score=0.148, total=   2.6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:  3.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=OneVsRestClassifier(estimator=SVC(C=1.0,\n",
              "                                                         break_ties=False,\n",
              "                                                         cache_size=200,\n",
              "                                                         class_weight=None,\n",
              "                                                         coef0=0.0,\n",
              "                                                         decision_function_shape='ovr',\n",
              "                                                         degree=3,\n",
              "                                                         gamma='scale',\n",
              "                                                         kernel='rbf',\n",
              "                                                         max_iter=-1,\n",
              "                                                         probability=False,\n",
              "                                                         random_state=None,\n",
              "                                                         shrinking=True,\n",
              "                                                         tol=0.001,\n",
              "                                                         verbose=False),\n",
              "                                           n_jobs=None),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'estimator__C': [1, 100, 1000],\n",
              "                         'estimator__gamma': ['scale', 'auto', 1, 0.1, 0.01,\n",
              "                                              0.001],\n",
              "                         'estimator__kernel': ['rbf']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7onn-eBaq8eH",
        "outputId": "fd26d415-6c80-45af-f54e-cb4c46921a37"
      },
      "source": [
        "print(rbf.best_params_)\n",
        "print(rbf.best_estimator_)\n",
        "y_pred = rbf.predict(X_test_multilabel)\n",
        "print(\"Accuracy :\",metrics.accuracy_score(y_test,y_pred))\n",
        "print(\"Macro f1 score :\",metrics.f1_score(y_test, y_pred, average = 'macro'))\n",
        "print(\"Micro f1 scoore :\",metrics.f1_score(y_test, y_pred, average = 'micro'))\n",
        "print(\"Hamming loss :\",metrics.hamming_loss(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'estimator__C': 1, 'estimator__gamma': 'scale', 'estimator__kernel': 'rbf'}\n",
            "OneVsRestClassifier(estimator=SVC(C=1, break_ties=False, cache_size=200,\n",
            "                                  class_weight=None, coef0=0.0,\n",
            "                                  decision_function_shape='ovr', degree=3,\n",
            "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
            "                                  probability=False, random_state=None,\n",
            "                                  shrinking=True, tol=0.001, verbose=False),\n",
            "                    n_jobs=None)\n",
            "Accuracy : 0.1\n",
            "Macro f1 score : 0.0\n",
            "Micro f1 scoore : 0.0\n",
            "Hamming loss : 0.013666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}